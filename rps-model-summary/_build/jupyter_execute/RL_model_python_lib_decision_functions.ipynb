{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b3ad81",
   "metadata": {},
   "source": [
    "# `RL_model_decision_functions.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d53174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for converting counts to probabilities, evaluating agent decision and outcomes\n",
    "\"\"\"\n",
    "\n",
    "# from utils import *\n",
    "import random\n",
    "from random import choices\n",
    "\n",
    "\n",
    "#########################\n",
    "## softmax probability ##\n",
    "#########################\n",
    "\n",
    "def softmax(x, beta = 1):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x * beta) / np.sum(np.exp(x * beta), axis=0)\n",
    "\n",
    "def get_softmax_probabilities(df, columns):\n",
    "    \"\"\"\n",
    "    create a softmax dataframe to store the probabilities for choosing\n",
    "    rock, paper, or scissors move.\n",
    "    This general sofm function is used for human_reward_move model.\n",
    "    \"\"\"\n",
    "    vals = df[columns]\n",
    "    vals = vals.apply(softmax,axis=1,beta=4)\n",
    "    return vals\n",
    "\n",
    "def get_softmax_probabilities_3b(df):\n",
    "    \"\"\"\n",
    "    create a softmax dataframe to store the probabilities for choosing\n",
    "    rock, paper, or scissors move.\n",
    "    This sofm function is used for human_reward_past_cur_move model.\n",
    "    \"\"\"\n",
    "    distribution = []\n",
    "    # assign vals to store reward list\n",
    "    # Since first round has no previous moves, we add even probability to it\n",
    "    vals=[[0.33,0.33,0.33]]\n",
    "    for i in range(2,df.shape[0],2):\n",
    "        # agent's previous move\n",
    "        pre_move=df.get('player_move').iloc[i-2]\n",
    "        # avoid Nan pre_move\n",
    "        if pre_move != 'none' and not pd.isna(pre_move):\n",
    "            # get the reward combination with specific pre_move\n",
    "            reward_cols=[f'{pre_move}_rock_reward',f'{pre_move}_paper_reward',f'{pre_move}_scissors_reward']\n",
    "            val = df[reward_cols].iloc[i].tolist()\n",
    "            vals.append(val) # append reward value to vals\n",
    "        else:\n",
    "            # if there's no pre_move, use the last reward list (val)\n",
    "            val=vals[-1]\n",
    "            vals.append(val)\n",
    "    # convert reward list to softmax probability\n",
    "    soft_max=[softmax(x) for x in vals]\n",
    "    # create a softmax distribution dataframe\n",
    "    sofm = pd.DataFrame(soft_max, columns = ['softmax_prob_rock', 'softmax_prob_paper', 'softmax_prob_scissors'])\n",
    "\n",
    "    # only human rows\n",
    "    df_new = df[df.is_bot == 0].reset_index()\n",
    "    # concate human rows and softmax distribution\n",
    "    df_new = pd.concat([df_new,sofm], axis = 1)\n",
    "    return df_new\n",
    "\n",
    "def get_softmax_probabilities_3c(df):\n",
    "    '''\n",
    "    generate softmax probability distribution of each round so we can sample moves from the distribution\n",
    "    '''\n",
    "    # df.dropna(axis = 0)\n",
    "    distribution = []\n",
    "    vals=[[0.33,0.33,0.33]] # has deleted one default prob list\n",
    "    for i in range(2,df.shape[0],2):\n",
    "        pre_move=df.get('player_move').iloc[i-1] # -1 instead of -2 since opponent_pre\n",
    "        if pre_move != 'none' and not pd.isna(pre_move):\n",
    "            reward_cols=[f'opponent_{pre_move}_rock_reward',f'opponent_{pre_move}_paper_reward',f'opponent_{pre_move}_scissors_reward']\n",
    "            val = df[reward_cols].iloc[i].tolist()\n",
    "            vals.append(val)\n",
    "        else:\n",
    "            val=vals[-1]\n",
    "            vals.append(val)\n",
    "    soft_max=[softmax(x) for x in vals]\n",
    "    sofm = pd.DataFrame(soft_max, columns = ['softmax_prob_rock', 'softmax_prob_paper', 'softmax_prob_scissors'])\n",
    "\n",
    "    # strip only human df outside of the function\n",
    "    df_new = df[df.is_bot == 0].reset_index()\n",
    "    df_new = pd.concat([df_new,sofm], axis = 1)\n",
    "    return df_new\n",
    "\n",
    "def get_softmax_probabilities_mix(df_agent_past,df_opponent_past):\n",
    "    \"\"\"\n",
    "    choose human_reward_past or opponent_reward_past based on which strategy has higher reward\n",
    "    \"\"\"\n",
    "    \n",
    "    distribution = []\n",
    "    vals=[[0.33,0.33,0.33]] # has deleted one default prob list\n",
    "    for i in range(2,max(df_agent_past.shape[0],df_agent_past.shape[0]),2):\n",
    "        oppo_pre_move=df_agent_past.get('player_move').iloc[i-1]\n",
    "        agent_pre_move=df_agent_past.get('player_move').iloc[i-2]\n",
    "        \n",
    "        if agent_pre_move != 'none' and oppo_pre_move!= 'none' and not pd.isna(oppo_pre_move) and not pd.isna(agent_pre_move):\n",
    "            agent_reward_cols=[f'{agent_pre_move}_rock_reward',\n",
    "                         f'{agent_pre_move}_paper_reward',\n",
    "                         f'{agent_pre_move}_scissors_reward'] #df_agent_past only has bot 0\n",
    "            oppo_reward_cols=[f'opponent_{oppo_pre_move}_rock_reward',\n",
    "                         f'opponent_{oppo_pre_move}_paper_reward',\n",
    "                         f'opponent_{oppo_pre_move}_scissors_reward']# df_opponent_past has bot=0&1,so index not match\n",
    "            val_agent=df_agent_past[agent_reward_cols].iloc[i].tolist()\n",
    "            val_oppo = df_opponent_past[oppo_reward_cols].iloc[i].tolist()\n",
    "            if sum(val_agent)>sum(val_oppo):\n",
    "                val=val_agent\n",
    "            else:\n",
    "                val=val_oppo\n",
    "            vals.append(val)\n",
    "        else:\n",
    "            val=vals[-1]\n",
    "            vals.append(val)\n",
    "            \n",
    "    soft_max=[softmax(x) for x in vals] \n",
    "    sofm = pd.DataFrame(soft_max, columns = ['softmax_prob_rock', 'softmax_prob_paper', 'softmax_prob_scissors'])\n",
    "    \n",
    "    # strip only human df outside of the function\n",
    "    df_new = df_agent_past[df_agent_past.is_bot == 0].reset_index() \n",
    "    df_new = pd.concat([df_new,sofm], axis = 1)\n",
    "    return df_new\n",
    "\n",
    "#############################\n",
    "### Move choice functions ###\n",
    "#############################\n",
    "\n",
    "def pick_move(df, sofm):\n",
    "    \"\"\"\n",
    "    pick agent move based of the softmax probability distribution\n",
    "    \"\"\"\n",
    "    moves = np.array([])\n",
    "    for i in range(df.shape[0]):\n",
    "        move_choices = ['rock', 'paper', 'scissors']\n",
    "        distribution = sofm.iloc[i].tolist()\n",
    "        chosen_move = choices(move_choices, distribution)\n",
    "        moves = np.append(moves, chosen_move)\n",
    "    df = df.assign(agent_move = moves)\n",
    "\n",
    "    return df\n",
    "\n",
    "def pick_move_3b(df):\n",
    "    moves = np.array([])\n",
    "    for i in range(df.shape[0]):\n",
    "        move_choices = ['rock', 'paper', 'scissors']\n",
    "        distribution = df[['softmax_prob_rock', 'softmax_prob_paper', 'softmax_prob_scissors']].iloc[i].tolist() # get ith [rock_prob,paper_prob,scissors_prob] from input df\n",
    "        chosen_move = random.choices(move_choices, distribution)\n",
    "        moves = np.append(moves, chosen_move)\n",
    "    df = df.assign(agent_move = moves) # agent_move stores sampled moves\n",
    "    return df\n",
    "\n",
    "def pick_move_3c(df):\n",
    "    '''\n",
    "    sample agent move based on softmax distribution\n",
    "    '''\n",
    "    moves = np.array([])\n",
    "    for i in range(df.shape[0]):\n",
    "        move_choices = ['rock', 'paper', 'scissors']\n",
    "        distribution = df[['softmax_prob_rock', 'softmax_prob_paper', 'softmax_prob_scissors']].iloc[i].tolist() # get ith [rock_prob,paper_prob,scissors_prob] from input df\n",
    "        chosen_move = random.choices(move_choices, distribution)\n",
    "        moves = np.append(moves, chosen_move)\n",
    "    df = df.assign(agent_move = moves) # agent_move stores sampled moves\n",
    "    return df\n",
    "\n",
    "def pick_move_3d(df):\n",
    "    moves = np.array([])\n",
    "    for i in range(df.shape[0]):\n",
    "        move_choices = ['rock', 'paper', 'scissors']\n",
    "        distribution = df[['softmax_prob_rock', 'softmax_prob_paper', 'softmax_prob_scissors']].iloc[i].tolist() # get ith [rock_prob,paper_prob,scissors_prob] from input df \n",
    "        chosen_move = random.choices(move_choices, distribution) \n",
    "        moves = np.append(moves, chosen_move)\n",
    "    df = df.assign(agent_move = moves) # agent_move stores sampled moves\n",
    "    return df\n",
    "\n",
    "def assign_agent_outcomes(df):\n",
    "    \"\"\"\n",
    "    Assign outcomes for the agent based on agent move choices.\n",
    "    df should include only human rows, since agent outcomes are irrelevant for simulating bots\n",
    "    \"\"\"\n",
    "    df.assign(agent_outcome = '')\n",
    "    df=df.assign(agent_outcome=df.apply(lambda x: evaluate_outcome(x['agent_move'], x['opponent_move']), axis=1))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ac3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}